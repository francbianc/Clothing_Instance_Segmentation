{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os, json, math, time, tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "from zipfile import ZipFile\n",
    "from pycocotools import mask as maskUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deepfashion2 to COCO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2coco(path_annos_image:str, num_images:int, output_dir:str):\n",
    "    \"\"\"Convert DF2 annotation format to COCO.\n",
    "    Args:\n",
    "        path_annos_image: (str) path of annos and image folders\n",
    "        num_images: (int) number of images == number of annos files\n",
    "        output_dir: (str) path where to save new json\n",
    "    \n",
    "    :return: json file with COCO annotations\n",
    "    \"\"\"\n",
    "    dataset = {\n",
    "        \"info\": {},\n",
    "        \"licenses\": [],\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": []\n",
    "    }\n",
    "\n",
    "    ### Categories\n",
    "    keypoints = [str(i) for i in range(1,295)]\n",
    "    categories = [[1, 'short_sleeved_shirt'], \n",
    "             [2, 'long_sleeved_shirt'],\n",
    "             [3, 'short_sleeved_outwear'],\n",
    "             [4, 'long_sleeved_outwear'],\n",
    "             [5, 'vest'],\n",
    "             [6, 'sling'],\n",
    "             [7, 'shorts'],\n",
    "             [8, 'trousers'],\n",
    "             [9, 'skirt'],\n",
    "             [10, 'short_sleeved_dress'],\n",
    "             [11, 'long_sleeved_dress'],\n",
    "             [12, 'vest_dress'],\n",
    "             [13, 'sling_dress']]\n",
    "\n",
    "    dataset['categories'] = [{'id': categories[i][0], \n",
    "                             'name': categories[i][1],\n",
    "                             'supercategory': 'clothes',\n",
    "                             'keypoints': keypoints,\n",
    "                             'skeleton': []} for i in range(len(categories))]\n",
    "    \n",
    "    assert len(os.listdir(path_annos_image+'/image')) == len(os.listdir(path_annos_image+'/annos')) == num_images \n",
    "\n",
    "    ### Images / Annotations\n",
    "    sub_index = 0 # the index of ground truth instance\n",
    "    for num in tqdm.tqdm(range(1, num_images+1)):\n",
    "        json_name = path_annos_image+'/annos/' + str(num).zfill(6)+'.json'\n",
    "        image_name = path_annos_image+'/image/' + str(num).zfill(6)+'.jpg'\n",
    "\n",
    "        if (num>=0):\n",
    "            shp = cv2.imread(image_name).shape\n",
    "            width, height = shp[1], shp[0]\n",
    "            temp = json.load(open(json_name))\n",
    "            pair_id = temp['pair_id']\n",
    "            source = temp['source']\n",
    "\n",
    "            dataset['images'].append({\n",
    "                'coco_url': '',\n",
    "                'date_captured': '',\n",
    "                'file_name': str(num).zfill(6) + '.jpg',\n",
    "                'flickr_url': '',\n",
    "                'id': num,\n",
    "                'license': 0,\n",
    "                'width': width,\n",
    "                'height': height,\n",
    "                'pair_id': pair_id,\n",
    "                'source': source})\n",
    "\n",
    "            for i in temp.keys(): # for each item \n",
    "                if i == 'source' or i=='pair_id':\n",
    "                    continue\n",
    "                else:\n",
    "                    points = np.zeros(294 * 3)\n",
    "                    sub_index = sub_index + 1\n",
    "                    box = temp[i]['bounding_box']\n",
    "                    w = box[2]-box[0]\n",
    "                    h = box[3]-box[1]\n",
    "                    x_1 = box[0]\n",
    "                    y_1 = box[1]\n",
    "                    bbox = [x_1,y_1,w,h]\n",
    "                    cat = temp[i]['category_id']\n",
    "                    seg = temp[i]['segmentation']\n",
    "\n",
    "                    style = temp[i]['style']\n",
    "                    scale = temp[i]['scale']\n",
    "                    occlusion = temp[i]['occlusion']\n",
    "                    viewpoint = temp[i]['viewpoint']\n",
    "                    zoom_in = temp[i]['zoom_in']\n",
    "\n",
    "                    landmarks = temp[i]['landmarks']\n",
    "                    points_x = landmarks[0::3]\n",
    "                    points_y = landmarks[1::3]\n",
    "                    points_v = landmarks[2::3]\n",
    "                    points_x = np.array(points_x)\n",
    "                    points_y = np.array(points_y)\n",
    "                    points_v = np.array(points_v)\n",
    "\n",
    "                    if cat == 1:\n",
    "                        for n in range(0, 25):\n",
    "                            points[3 * n] = points_x[n]\n",
    "                            points[3 * n + 1] = points_y[n]\n",
    "                            points[3 * n + 2] = points_v[n]\n",
    "                    elif cat ==2:\n",
    "                        for n in range(25, 58):\n",
    "                            points[3 * n] = points_x[n - 25]\n",
    "                            points[3 * n + 1] = points_y[n - 25]\n",
    "                            points[3 * n + 2] = points_v[n - 25]\n",
    "                    elif cat ==3:\n",
    "                        for n in range(58, 89):\n",
    "                            points[3 * n] = points_x[n - 58]\n",
    "                            points[3 * n + 1] = points_y[n - 58]\n",
    "                            points[3 * n + 2] = points_v[n - 58]\n",
    "                    elif cat == 4:\n",
    "                        for n in range(89, 128):\n",
    "                            points[3 * n] = points_x[n - 89]\n",
    "                            points[3 * n + 1] = points_y[n - 89]\n",
    "                            points[3 * n + 2] = points_v[n - 89]\n",
    "                    elif cat == 5:\n",
    "                        for n in range(128, 143):\n",
    "                            points[3 * n] = points_x[n - 128]\n",
    "                            points[3 * n + 1] = points_y[n - 128]\n",
    "                            points[3 * n + 2] = points_v[n - 128]\n",
    "                    elif cat == 6:\n",
    "                        for n in range(143, 158):\n",
    "                            points[3 * n] = points_x[n - 143]\n",
    "                            points[3 * n + 1] = points_y[n - 143]\n",
    "                            points[3 * n + 2] = points_v[n - 143]\n",
    "                    elif cat == 7:\n",
    "                        for n in range(158, 168):\n",
    "                            points[3 * n] = points_x[n - 158]\n",
    "                            points[3 * n + 1] = points_y[n - 158]\n",
    "                            points[3 * n + 2] = points_v[n - 158]\n",
    "                    elif cat == 8:\n",
    "                        for n in range(168, 182):\n",
    "                            points[3 * n] = points_x[n - 168]\n",
    "                            points[3 * n + 1] = points_y[n - 168]\n",
    "                            points[3 * n + 2] = points_v[n - 168]\n",
    "                    elif cat == 9:\n",
    "                        for n in range(182, 190):\n",
    "                            points[3 * n] = points_x[n - 182]\n",
    "                            points[3 * n + 1] = points_y[n - 182]\n",
    "                            points[3 * n + 2] = points_v[n - 182]\n",
    "                    elif cat == 10:\n",
    "                        for n in range(190, 219):\n",
    "                            points[3 * n] = points_x[n - 190]\n",
    "                            points[3 * n + 1] = points_y[n - 190]\n",
    "                            points[3 * n + 2] = points_v[n - 190]\n",
    "                    elif cat == 11:\n",
    "                        for n in range(219, 256):\n",
    "                            points[3 * n] = points_x[n - 219]\n",
    "                            points[3 * n + 1] = points_y[n - 219]\n",
    "                            points[3 * n + 2] = points_v[n - 219]\n",
    "                    elif cat == 12:\n",
    "                        for n in range(256, 275):\n",
    "                            points[3 * n] = points_x[n - 256]\n",
    "                            points[3 * n + 1] = points_y[n - 256]\n",
    "                            points[3 * n + 2] = points_v[n - 256]\n",
    "                    elif cat == 13:\n",
    "                        for n in range(275, 294):\n",
    "                            points[3 * n] = points_x[n - 275]\n",
    "                            points[3 * n + 1] = points_y[n - 275]\n",
    "                            points[3 * n + 2] = points_v[n - 275]\n",
    "                    num_points = len(np.where(points_v > 0)[0])\n",
    "\n",
    "                    dataset['annotations'].append({\n",
    "                        'image_id': num,\n",
    "                        'category_id': cat,\n",
    "                        'id': sub_index,\n",
    "\n",
    "                        'bbox': bbox,\n",
    "                        'area': w*h,\n",
    "                        'segmentation': seg,\n",
    "\n",
    "                        'iscrowd': 0,\n",
    "                        'num_keypoints':num_points,\n",
    "                        'keypoints':points.tolist(),\n",
    "\n",
    "                        'style': style,\n",
    "                        'scale': scale, \n",
    "                        'occlusion': occlusion,\n",
    "                        'viewpoint': viewpoint,\n",
    "                        'zoom_in': zoom_in\n",
    "                    })\n",
    "\n",
    " \n",
    "    with open(output_dir, 'w') as f:\n",
    "        json.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF2_DATA_DIR = '.../datasets/deepfashion2' #@@@ OVERRIDE: Path of folder with DF2 annotations\n",
    "\n",
    "# CHECKS\n",
    "# Check number of images = number of annotation files\n",
    "images_names_tr = sorted(os.listdir(os.path.join(DF2_DATA_DIR, 'train/image'))) \n",
    "annos_names_tr = sorted(os.listdir(os.path.join(DF2_DATA_DIR, 'train/annos')))\n",
    "assert len(images_names_tr) == len(annos_names_tr)\n",
    "\n",
    "images_names_val = sorted(os.listdir(os.path.join(DF2_DATA_DIR, 'validation/image'))) \n",
    "annos_names_val = sorted(os.listdir(os.path.join(DF2_DATA_DIR, 'validation/annos')))\n",
    "assert len(images_names_val) == len(annos_names_val)\n",
    "\n",
    "# Check there is 1 and only 1 annotation file for each immage\n",
    "for i in range(len(images_names_tr)):\n",
    "    assert annos_names_tr[i].split('.')[0] == images_names_tr[i].split('.')[0]\n",
    "    \n",
    "for i in range(len(images_names_val)):\n",
    "    assert annos_names_val[i].split('.')[0] == images_names_val[i].split('.')[0]  \n",
    "\n",
    "# CONVERT!\n",
    "df2coco(os.path.join(DF2_DATA_DIR, 'train'), len(images_names_tr), 'df2_annos_tr.json')\n",
    "df2coco(os.path.join(DF2_DATA_DIR, 'validation'), len(images_names_val), 'df2_annos_val.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG Image Annotator to COCO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def via2coco(via_json_path, ontology_path, img_path, source, output_dir):\n",
    "    \"\"\"Convert a json from VGG Image Annotator (VIA) format to COCO.\n",
    "    Args:\n",
    "        via_json_path: (str) path of VIA json file\n",
    "        ontology_path: (str) path of xlsx file with categories\n",
    "        source: (str) source of images (user/shop/IG/user_shop)\n",
    "        img_path: (str) path of folder with images\n",
    "        output_dir: (str) path where to save new json\n",
    "    \n",
    "    :return: json file with COCO annotations\n",
    "    \"\"\"\n",
    "    via = json.load(open(via_json_path, encoding=\"utf-8\"))\n",
    "    ont_df = pd.read_excel(ontology_path, sheet_name=0, engine=\"openpyxl\")\n",
    "\n",
    "    coco = {\n",
    "        \"info\": {},\n",
    "        \"licenses\": [],\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": []\n",
    "    }\n",
    "\n",
    "    coco['info'] = {\n",
    "        \"description\": via['_via_settings']['project']['name'],\n",
    "        \"version\": \"1.0\",\n",
    "        \"VIA_version\": via['_via_data_format_version'],\n",
    "        \"year\": 2022,\n",
    "        \"date_created\": time.asctime(time.localtime(time.time()))\n",
    "    }\n",
    "\n",
    "    via_cats = via['_via_attributes']['region']['clothing']['options']\n",
    "    for k,v in tqdm.tqdm(via_cats.items()):\n",
    "        rows, cols = np.where(ont_df == v)\n",
    "        if ont_df.columns[cols[0]-1] == 'category':\n",
    "            cat = ont_df.iloc[rows[0], cols[0]-1]\n",
    "            sup = ont_df.iloc[rows[0], cols[0]-2]\n",
    "        else:   \n",
    "            cat, sup = '', ont_df.iloc[rows[0], cols[0]-1]\n",
    "        c = {\n",
    "            'id': int(k), \n",
    "            'name': v.strip().replace(' ', '_').lower(),\n",
    "            'category': cat,\n",
    "            'supercategory': sup}\n",
    "        coco['categories'].append(c)\n",
    "    \n",
    "    id = 0\n",
    "    for k,v in tqdm.tqdm(via['_via_img_metadata'].items()):\n",
    "        if 'clothing' in v['regions'][0]['region_attributes'].keys():\n",
    "            # Images\n",
    "            k = int(v['filename'][:-4])\n",
    "            assert int(k) == int(v['filename'][:-4])\n",
    "            shp = cv2.imread(os.path.join(img_path, v['filename'])).shape\n",
    "            img = {\n",
    "                \"id\": int(k),\n",
    "                \"file_name\": v['filename'],\n",
    "                \"width\": shp[1],\n",
    "                \"height\": shp[0],\n",
    "                \"source\" : source, \n",
    "                \"people\" : list(v['file_attributes']['people'])}\n",
    "            coco['images'].append(img)\n",
    "\n",
    "            # Annotations\n",
    "            for region in v['regions']:\n",
    "                cat_id = int(region['region_attributes']['clothing'])\n",
    "                assert cat_id in (d['id'] for d in coco['categories'])\n",
    "                points_x = region['shape_attributes']['all_points_x']\n",
    "                points_y = region['shape_attributes']['all_points_y']\n",
    "\n",
    "                seg = [] # There will be just 1 polygon for 1 instance in VIA format\n",
    "                for x, y in zip(points_x, points_y):\n",
    "                    seg.append(x)\n",
    "                    seg.append(y)\n",
    "                segmentation = [seg]\n",
    "\n",
    "                rles = maskUtils.frPyObjects(segmentation, shp[0], shp[1])\n",
    "                rle = maskUtils.merge(rles) # If a single object consist of multiple parts, merge all parts into 1 RLE\n",
    "                area = maskUtils.area(rle).astype(float)\n",
    "                bbox = list(maskUtils.toBbox(rle))\n",
    "                \n",
    "                ann = {\n",
    "                    \"id\": id,\n",
    "                    \"image_id\": int(k),\n",
    "                    \"category_id\": cat_id, # int\n",
    "                    \"iscrowd\": 0,\n",
    "                    \"area\": area,  # float\n",
    "                    \"bbox\": bbox,  # [x,y,w,h]\n",
    "                    \"segmentation\": segmentation  # [x1,y1,x2,y2,...]\n",
    "                }\n",
    "                id += 1\n",
    "                coco['annotations'].append(ann)\n",
    "    \n",
    "    with open(output_dir, 'w') as f:\n",
    "        json.dump(coco, f)\n",
    "    return coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@@@ OVERRIDE\n",
    "DIR_VIA_JSON = '.../via.json' # Path of json file with the VIA annotations\n",
    "DIR_XLSX_ONTOLOGY = './tools/fashion_ontology.xlsx' # Path of excel file with fashion ontolgy\n",
    "DIR_IMAGES = '.../images' # Path of folder with images (whose annotations have been saved in the VIA json file)\n",
    "\n",
    "coco = via2coco(DIR_VIA_JSON, DIR_XLSX_ONTOLOGY, DIR_IMAGES, '', './coco.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
